import os
import json
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
from collections import Counter

# ì‹œí€€ìŠ¤ ë°ì´í„°ê°€ ì €ì¥ëœ ë””ë ‰í„°ë¦¬
DATA_DIR = "data/seq"

# ë°ì´í„°ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
motion_data = []
labels = []
label_map = {}

# ë°ì´í„° ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
if not os.path.exists(DATA_DIR):
    print("ì‹œí€€ìŠ¤ ë°ì´í„° í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
    exit()

# ì‹œí€€ìŠ¤ ë°ì´í„°(.npy) ë¡œë“œ
for root, dirs, files in os.walk(DATA_DIR):  # ğŸ”¥ í•˜ìœ„ í´ë”ê¹Œì§€ íƒìƒ‰
    for file in files:
        if not file.endswith(".npy") or not file.startswith("seq_"):
            continue

        filepath = os.path.join(root, file)

        try:
            data = np.load(filepath)
            # ì‹œí€€ìŠ¤ ê¸¸ì´ ê²€ì¦ (60í”„ë ˆì„)
            if len(data.shape) != 2 or data.shape[0] != 30:
                print(f"{file} í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. ê±´ë„ˆëœ€.")
                continue
        except Exception as e:
            print(f"{file} ë¡œë”© ì˜¤ë¥˜: {e}")
            continue

        # ğŸ”‘ í´ë”ëª…ì„ ë¼ë²¨ë¡œ ì‚¬ìš© (ex: "one", "bo", "gun")
        label_name = os.path.basename(root)

        # ìƒˆë¡œìš´ ë¼ë²¨ì´ë©´ ë§µì— ì¶”ê°€
        if label_name not in label_map:
            label_map[label_name] = len(label_map)

        # ë°ì´í„°ì™€ ë¼ë²¨ ì¶”ê°€
        motion_data.append(data.tolist())
        labels.append(label_map[label_name])

# ë¼ë²¨ ë¶„í¬ ì¶œë ¥
print("ë¼ë²¨ ë¶„í¬:", Counter(labels))

# ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ì¢…ë£Œ
if len(motion_data) == 0:
    print("í•™ìŠµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# ì…ë ¥ ë°ì´í„°ì˜ ì‹œí€€ìŠ¤ ê¸¸ì´ì™€ íŠ¹ì§• ìˆ˜ íŒŒì•…
max_seq_len = max(len(seq) for seq in motion_data)       # ì‹œí€€ìŠ¤ ê¸¸ì´ (ì˜ˆ: 60)
feature_len = len(motion_data[0][0])                      # íŠ¹ì§• ìˆ˜ (ì˜ˆ: 50)

# ë¦¬ìŠ¤íŠ¸ë¥¼ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜
X_padded = np.array(motion_data, dtype=np.float32)
y = np.array(labels, dtype=np.int32)

# í•™ìŠµìš© / ê²€ì¦ìš© ë°ì´í„° ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)

# ì´ í´ë˜ìŠ¤ ìˆ˜ ê³„ì‚°
num_classes = len(label_map)

# ğŸ”§ LSTM ëª¨ë¸ êµ¬ì„±
model = keras.Sequential([
    keras.layers.Masking(mask_value=0.0, input_shape=(max_seq_len, feature_len)),  # 0ìœ¼ë¡œ ì±„ìš´ ë¶€ë¶„ ë¬´ì‹œ
    keras.layers.LSTM(64),                         # LSTM ë ˆì´ì–´
    keras.layers.Dense(64, activation="relu"),     # ì™„ì „ ì—°ê²°ì¸µ
    keras.layers.Dense(num_classes, activation="softmax")  # í´ë˜ìŠ¤ ìˆ˜ë§Œí¼ ì¶œë ¥
])

# ëª¨ë¸ ì»´íŒŒì¼
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# ëª¨ë¸ í•™ìŠµ ì‹œì‘
model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))

# í•™ìŠµëœ ëª¨ë¸ êµ¬ì¡°ì™€ ê°€ì¤‘ì¹˜ ì €ì¥
with open("hand_gesture_model.json", "w") as json_file:
    json_file.write(model.to_json())
model.save_weights("hand_gesture_weights.h5")

# ë¼ë²¨ ë§µ ì €ì¥ (ë‚˜ì¤‘ì— ì˜ˆì¸¡ ì‹œ ì‚¬ìš©)
with open("label_map.json", "w", encoding="utf-8") as f:
    json.dump(label_map, f, ensure_ascii=False, indent=4)

print("ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
